{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c449d5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e8c5712",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataloaders import InfiniteDataLoader\n",
    "from datasets import SubclassedDataset\n",
    "from models import TransferModel18\n",
    "from utils.image_data_utils import images_to_df, get_features\n",
    "from utils.cluster_utils import train_erm_cluster, extract_features, features_to_df, split_features, check_cluster\n",
    "from umap import UMAP\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa8470b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_sc(tr_loader, cv_loader, tst_loader, images_df, split_path='./data/train_test_splits/LIDC_data_split.csv', split_num=None, get_cv_embeds=False, device='cpu'):\n",
    "\n",
    "    model = TransferModel18(pretrained=True, freeze=False, device=device)\n",
    "    train_erm_cluster(model, device=device, loaders=(\n",
    "        tr_loader, cv_loader, tst_loader))\n",
    "\n",
    "    noduleID, features = extract_features(\n",
    "        model, images_df=images_df, device=device)\n",
    "\n",
    "    df_features_all = features_to_df(noduleID, features)\n",
    "  \n",
    "\n",
    "    # features and corresponding malignancy, noduleID\n",
    "    train_f, cv_test_f = split_features(\n",
    "        df_features_all, split_path=split_path, split_num=split_num)\n",
    "\n",
    "    reducer = UMAP(random_state=8)\n",
    "    reducer.fit(train_f[0])\n",
    "\n",
    "    train_e, cv_test_e = reducer.transform(\n",
    "        train_f[0]), reducer.transform(cv_test_f[0])\n",
    "\n",
    "    malig_max = np.argmax(check_cluster(train_e[train_f[1] > 1]))+2\n",
    "    benig_max = np.argmax(check_cluster(train_e[train_f[1] <= 1]))+2\n",
    "\n",
    "    return malig_max, benig_max, df_features_all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e21aa603",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_file = './data/train_test_splits/LIDC_data_split.csv' #'./data/train_test_splits/Nodule_Level_30Splits/nodule_split_all.csv'\n",
    "split_df = pd.read_csv(split_file, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97555a4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>noduleID</th>\n",
       "      <th>split</th>\n",
       "      <th>malignancy</th>\n",
       "      <th>malignancy_b</th>\n",
       "      <th>spic_groups</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1483</th>\n",
       "      <td>2687</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1484</th>\n",
       "      <td>2688</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1485</th>\n",
       "      <td>2689</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1486</th>\n",
       "      <td>2690</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1487</th>\n",
       "      <td>2691</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1488 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      noduleID  split  malignancy  malignancy_b  spic_groups\n",
       "0            1      2           3             1            3\n",
       "1            2      0           3             1            2\n",
       "2            3      0           3             1            3\n",
       "3            4      0           2             1            3\n",
       "4            5      0           2             1            2\n",
       "...        ...    ...         ...           ...          ...\n",
       "1483      2687      2           2             1            3\n",
       "1484      2688      1           1             0            0\n",
       "1485      2689      0           1             0            0\n",
       "1486      2690      0           3             1            3\n",
       "1487      2691      0           1             0            0\n",
       "\n",
       "[1488 rows x 5 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_file = './data/train_test_splits/LIDC_data_split.csv' #'./data/train_test_splits/Nodule_Level_30Splits/nodule_split_all.csv'\n",
    "split_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27768782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 306.00 MiB (GPU 0; 8.00 GiB total capacity; 5.94 GiB already allocated; 0 bytes free; 6.21 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_40012\\1464615559.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m train_data, cv_data, test_data = get_features(\n\u001b[1;32m---> 12\u001b[1;33m     images=True, features=images_df, device=DEVICE, subclass='malignancy')\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;31m# datasets\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\LIDC_GDRO\\utils\\image_data_utils.py\u001b[0m in \u001b[0;36mget_features\u001b[1;34m(feature_file, split_file, subclass_file, images, features, device, subclass, split_num)\u001b[0m\n\u001b[0;32m    247\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mimg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'image'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    248\u001b[0m                     \u001b[0mimgs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maugment_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 249\u001b[1;33m                 \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    250\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m                 \u001b[1;31m# hacky way to repeat the labels for the additional augmented images\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 306.00 MiB (GPU 0; 8.00 GiB total capacity; 5.94 GiB already allocated; 0 bytes free; 6.21 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "split_file = './data/train_test_splits/LIDC_data_split.csv' #'./data/train_test_splits/Nodule_Level_30Splits/nodule_split_all.csv'\n",
    "split_df = pd.read_csv(split_file, index_col=0)\n",
    "# split_num = 0\n",
    "\n",
    "print('Loading images')\n",
    "images_df = images_to_df()\n",
    "\n",
    "df_clusters = pd.DataFrame()\n",
    "\n",
    "train_data, cv_data, test_data = get_features(\n",
    "    images=True, features=images_df, device=DEVICE, subclass='malignancy')\n",
    "\n",
    "# datasets\n",
    "tr = SubclassedDataset(*train_data)\n",
    "cv = SubclassedDataset(*cv_data)\n",
    "tst = SubclassedDataset(*test_data)\n",
    "\n",
    "# dataloaders\n",
    "tr_loader = InfiniteDataLoader(tr, batch_size=512)\n",
    "cv_loader = InfiniteDataLoader(cv, len(cv))\n",
    "tst_loader = InfiniteDataLoader(tst, len(tst))\n",
    "\n",
    "for trial in range(30):\n",
    "    print(f'==============  Trial {trial} ==============')\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    m, b, df_features = test_sc(tr_loader, cv_loader, tst_loader, images_df, device=DEVICE)\n",
    "    torch.cuda.empty_cache()\n",
    "    df_features.to_csv(\"./data/CNN_features/CNNeatures_{}.csv\".format(trial))\n",
    "    print(f'Malginant max sc: {m} Benign max sc:{b}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b5f3c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
